[{"content":"Introduction AI-assisted source code development is now growing at an exponential pace. The capabilities of LLMs provided by various vendors make it possible, even in Zero-Shot Learning mode, to generate high-quality source code with a remarkable level of abstraction and complexity. The results, surprisingly good in my opinion, come from using so‑called AI Agents (in ReAct mode and supported by MCP Servers), which significantly boost developer productivity.\nBut let’s pause for a moment. While the world is overflowing with enthusiasm and expectations, it is important to remember that source code generation by an LLM (agentic or not) is only one part of the software development process. The demand for Software Architects will remain high, precisely to avoid building software that, while technically working, is underperforming, hard to maintain, scale, and extend.\nWe have all worked on software projects which, although functional, carried a huge and hard‑to‑control technical debt. Time pressure and budget constraints often pushed quality down, leading to quick and dirty solutions that solved the immediate problem but increased the amount of inefficient source code and, in some cases, introduced security vulnerabilities.\nThe question is: in a phase where technologies are evolving so rapidly, can we really afford to make the same mistake again?\nThe answer must be no, also because, beyond technical debt, we now have ongoing costs to consider (AI service providers, vector databases, and more) that are anything but negligible.\nIf we use AI agents without a solid foundation in software design, we risk improvising architectures that work at first glance, but are neither scalable nor maintainable. Among the risks, we find:\n\u0026ldquo;Over-engineering\u0026rdquo;: designing systems that are far too complex for the problem at hand, with a consequent increase in the project’s ongoing costs. Inadequate performance due to suboptimal agent design, which can lead to longer response times and a disappointing user experience. Goal In this article, I will walk you through an exercise I carried out to experiment with a few agentic design patterns. The exercise is built around a small demo application called Agentic TotChef, whose goal is to generate a weekly menu for a 1‑year‑old girl, taking into account what she eats at daycare, recipes from the family cookbook, and what is currently available at home.\nThis experiment helped me understand both limitations and benefits, including:\nThe use of SLMs (Small Language Models) to keep costs under control while still achieving satisfying results The adoption of design patterns and best practices to architect AI agents with solid performance characteristics Small Language Models: limits and benefits While it is true that large language models (LLMs) like GPT‑5, Gemini, Claude, Grok, and others offer extraordinary capabilities, it is equally true that Small Language Models (SLMs) are gaining traction thanks to their efficiency and lower cost.\nSLMs, such as those provided by Ollama, are designed to be lighter and cheaper to run, making them ideal for focused applications that do not need the full power of a massive LLM.\nSome key advantages:\nLower cost: SLMs are generally cheaper to use than LLMs, which makes them accessible even for projects with limited budgets. Efficiency: SLMs can be faster at generating responses, especially for well‑framed tasks that do not require deep, open‑ended reasoning. Customization: By injecting task‑specific context, you can obtain more relevant and accurate outputs, squeezing the most out of the SLM. However, it is important to acknowledge their limitations, such as a reduced ability to handle very complex contexts or to generate highly creative, nuanced answers. So the choice between LLM and SLM should always depend on the project’s specific needs and the goals you want to achieve.\nIn my case, for the TotChef project, I chose qwen3‑8b, which proved more than sufficient to generate weekly menus that were both accurate and relevant. We are obviously talking about medium‑low complexity requirements and modest hardware. Still, it was enough to achieve a satisfying outcome with acceptable response times.\nAgentic Design Patterns: what they are During an intense reading session, I stumbled upon a very interesting book: Agentic Design Pattern by Antonio Gulli, Engineering Director at Google. The book describes a set of design patterns for building AI agents, with a particular focus on structuring agent workflows, handling memory, and interacting with the external environment.\nAs I was reading it, my mind immediately went to the GoF and their idea of standardizing source code production. In a way, the patterns described in Agentic Design Pattern represent an attempt to standardize the design of AI agents, offering proven solutions to recurring problems you encounter while building agentic systems.\nIn my sample project, Agentic TotChef, I did not have much room to apply a wide range of patterns, so I started by experimenting with the first two:\nPrompt Chaining: this pattern breaks down a complex task into a series of simpler steps, each handled by a dedicated AI agent. Parallelization: this pattern runs multiple AI agents in parallel to complete a task, improving overall performance and reducing response times. For me it was both a fun game and a practical way to better understand the limits and advantages of these design patterns, and how they can be applied in real projects to improve the maintainability of AI agents.\nAgentic TotChef: software architecture Agentic TotChef is a little toy project that I built for several reasons:\nTo test the design patterns from Agentic Design Pattern To see whether an SLM could deliver satisfying results To write boilerplate code (the part highlighted in purple in the diagram) for the design of OAIA - OrchestrAI Architecture, a reusable template for future projects. The diagram below illustrates the high-level architecture of Agentic TotChef:\nThe most interesting part of this tiny software architecture is the file Runner, highlighted in the green box on the right: it shows all the calls to qwen3‑8b and the interactions between the various agents.\nIn particular, you can clearly see how the Prompt Chaining design pattern is used to split the complex task of generating a weekly menu into a sequence of simpler steps, each implemented by a dedicated AI agent.\nThe Parallelization pattern, on the other hand, is used to run two independent steps in parallel:\nFetching the daycare menu and generating a lunch plan from Monday to Friday Creating an evening‑meal menu for the full week and weekend, taking into account what is available at home and the family recipes. While the first pattern helped achieve a clearly better output compared to a more naive design, the second allowed me to increase the speedup of the weekly menu generation process, reducing response times and improving the overall user experience.\nNote: I am not covering the small web application that lets you chat with TotChef, simply because it does not include any particularly interesting architectural elements: it is just an interface used to test the AI agents’ outputs at the various steps.\nAgentic TotChef: code snippet In this Python code example, each object that defines a step (for example KindergartenMenuStep) implements an execute method that runs the given step, interacting (via LLMExecutor) with qwen3‑8b and returning a StepResult object containing the step output and execution status.\nYou can find the full code here\n# Step 1: Kindergarten menu kg_step = KindergartenMenuStep() kg_step_output: StepResult = StepResult(step_id=kg_step.step_id, result=\u0026#34;\u0026#34;) # Step 2: Home menu home_step = HomeMenuStep() home_step_output = StepResult(step_id=home_step.step_id, result=\u0026#34;\u0026#34;) # Execute both steps in parallel with ProcessPoolExecutor() as executor: futures = [ executor.submit(kg_step.execute), executor.submit(home_step.execute) ] for future in futures: single_result = future.result() if single_result is not None and single_result.is_success(): if single_result.step_id == kg_step.step_id: kg_step_output: StepResult = single_result elif single_result.step_id == home_step.step_id: home_step_output: StepResult = single_result # Step 3: Merge menus merge_step = MergeMenuStep() merge_step_output: StepResult = merge_step.execute(kg_step_output.result, home_step_output.result) # Step 4: Shopping list shopping_list_step = ShoppingListStep() shopping_list_output: StepResult = shopping_list_step.execute(merge_step_output.result) # Add step that create a Markdown file with the merged menu and shopping list create_md_step = CreateMarkdownStep() create_md_output: StepResult = create_md_step.execute(merge_step_output.result, shopping_list_output.result) if create_md_output is not None and create_md_output.is_success(): TotChef.log_element(f\u0026#34;Markdown created: {create_md_output.result}\u0026#34;) else: TotChef.log_element(\u0026#34;Failed to create markdown file\u0026#34;) The output is a Markdown file that includes the weekly menu and the related shopping list.\nHere an example # Weekly Menu and Shopping List ## Menù | Day | Lunch | Dinner | |-----------|------------------------------------------------------------------------|------------------------------------------------------------------------| | Monday | First Course: Penne al ragù\u0026lt;br\u0026gt;Main Course: Omelette al forno\u0026lt;br\u0026gt;Side: Carote prezzemolate | First Course: Riso sugo e piselli\u0026lt;br\u0026gt;Main Course: Nasello con carote in padella\u0026lt;br\u0026gt;Side: Zucchine | | Tuesday | First Course: Minestrina in brodo vegetale\u0026lt;br\u0026gt;Main Course: Spezzatino di tacchino in umido\u0026lt;br\u0026gt;Side: Purea di patate | First Course: Pasta al ragù\u0026lt;br\u0026gt;Main Course: Polpette di carne\u0026lt;br\u0026gt;Side: Fagiolini | | Wednesday | First Course: Passato di lenticchie con pasta\u0026lt;br\u0026gt;Main Course: Stracchino\u0026lt;br\u0026gt;Side: Costine all'olio | First Course: Pasta alla zucca\u0026lt;br\u0026gt;Main Course: Orata in friggitrice ad aria\u0026lt;br\u0026gt;Side: Costine | | Thursday | First Course: Risotto alla parmigiana\u0026lt;br\u0026gt;Main Course: Bocconcini di pollo alla pizzaiola\u0026lt;br\u0026gt;Side: Finocchi lessi | First Course: Pasta alla crema di ceci\u0026lt;br\u0026gt;Main Course: Philadelphia\u0026lt;br\u0026gt;Side: Verza | | Friday | First Course: Farfalle al pomodoro\u0026lt;br\u0026gt;Main Course: Filetto di pesce al limone\u0026lt;br\u0026gt;Side: Broccoli all'olio | First Course: Pasta e patate\u0026lt;br\u0026gt;Main Course: Formaggio fresco\u0026lt;br\u0026gt;Side: Cavolo nero | | Saturday | First Course: Pasta al pomodoro\u0026lt;br\u0026gt;Main Course: Polpette di ceci\u0026lt;br\u0026gt;Side: Zucchine | First Course: Riso sugo e piselli\u0026lt;br\u0026gt;Main Course: Ricotta fresca\u0026lt;br\u0026gt;Side: Spinaci | | Sunday | First Course: Pasta al cavolo nero\u0026lt;br\u0026gt;Main Course: Frittata\u0026lt;br\u0026gt;Side: Fagiolini | First Course: Pasta alla crema di zucchine\u0026lt;br\u0026gt;Main Course: Orata in friggitrice ad aria\u0026lt;br\u0026gt;Side: Cavolfiore | ## Shopping List ### Fruits and Vegetables - Carote: 1 kg - Zucchine: 1 kg - Fagiolini: 1 kg - Broccoli: 1 kg - Finocchi: 1 kg - Cavolfiore: 1 kg - Cavolo nero: 1 kg - Spinaci: 1 kg - Piselli: 1 kg - Verza: 1 kg - Patate: 1 kg - Lenticchie: 1 kg - Riso: 1 kg - Cipolle: 1 kg - Aglio: 1 kg - Prezzemolo: 1 mazzetto - Basilico: 1 mazzetto - Timo: 1 mazzetto - Zafferano: 1 cucchiaino ### Proteins (Meat, Fish, Eggs, etc.) - Manzo: 1 kg - Tacchino: 1 kg - Pollo: 1 kg - Pesce (filetto): 1 kg - Orata: 1 kg - Uova: 12 pezzi - Stracchino: 200 g - Philadelphia: 200 g - Formaggio fresco: 200 g - Ricotta fresca: 200 g - Bocconcini di pollo: 1 kg ### Carbohydrates (Pasta, Rice, Bread, etc.) - Penne: 500 g - Farfalle: 500 g - Pasta alla crema di ceci: 500 g - Pasta alla zucca: 500 g - Pasta al cavolo nero: 500 g - Pasta alla crema di zucchine: 500 g - Riso: 1 kg - Pane: 1 kg ### Lacteos (Milk, Cheese, Yogurt, etc.) - Latte: 1 litro - Yogurt greco: 1 litro - Formaggio grattugiato: 100 g - Burro: 100 g ### Legumes - Ceci: 500 g - Lenticchie: 1 kg - Fagioli: 500 g ### Other (Oils, Spices, etc.) - Olio d'oliva: 1 litro - Sale: 1 kg - Pepe nero: 100 g - Zucchero: 1 kg - Aceto balsamico: 100 ml - Senape: 100 ml - Panna: 200 ml - Salsa di soia: 100 ml - Vino bianco: 1 litro - Olio per friggere: 500 ml - Farina: 500 g - Cioccolato fondente: 100 g - Cacao in polvere: 100 g - Caffè: 100 g - Zucchero di canna: 1 kg - Miele: 100 g Conclusions In this article, I shared an exercise focused on experimenting with a few agentic design patterns using the SLM qwen3-8b to generate a weekly menu suitable for a one-year-old child.\nThis experiment helped me identify both the strengths and limitations of these patterns, showing how they can be adopted in real-world scenarios to improve the maintainability and robustness of AI agents.\nIn particular, the Prompt Chaining pattern proved effective in breaking down a complex task into a sequence of more manageable steps, each handled by a specialized agent. The Parallelization pattern, on the other hand, made it possible to execute two independent steps simultaneously, boosting performance and noticeably reducing response time.\nThe resulting speedup achieved through this architecture was significant — around 1.5× for this use case — considering that only the two most demanding steps were run in parallel. Previous implementations, which lacked a clear separation of responsibilities and relied on monolithic agents, instead showed undesired behaviors like infinite loops and hallucinations.\nFor the development of Agentic TotChef, I used Python, but agentic design patterns are language-agnostic concepts that can be applied to any type of agent or AI model.\nThis project also gave me the chance to explore the world of vibe coding more deeply, thanks to the valuable insights of @gregoriolagamba, Solution Architect at Plenitude, who introduced me to agentic programming tools directly on GitHub.\n","permalink":"https://carmelolg.github.io/it-is-worth-a-coke/posts/ai-agentic-flow-architecture/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eAI-assisted source code development is now growing at an exponential pace.\nThe capabilities of LLMs provided by various vendors make it possible, even in \u003ca href=\"https://www.promptingguide.ai/techniques/zeroshot\"\u003eZero-Shot Learning\u003c/a\u003e mode, to generate high-quality source code with a remarkable level of abstraction and complexity.\nThe results, surprisingly good in my opinion, come from using so‑called \u003cstrong\u003eAI Agents\u003c/strong\u003e (in \u003ca href=\"https://www.promptingguide.ai/techniques/react\"\u003eReAct\u003c/a\u003e mode and supported by \u003ca href=\"https://modelcontextprotocol.io/docs/getting-started/intro\"\u003eMCP Servers\u003c/a\u003e), which significantly boost developer productivity.\u003c/p\u003e\n\u003cp\u003eBut let’s pause for a moment. While the world is overflowing with enthusiasm and expectations, it is important to remember that source code generation by an LLM (agentic or not)\n\u003cstrong\u003eis only one part of the software development process\u003c/strong\u003e. The demand for Software Architects will remain high, precisely to avoid building software\nthat, while technically working, is underperforming, hard to maintain, scale, and extend.\u003c/p\u003e","title":"Agentic TotChef: Software Architectures, Patterns, and Best Practices"}]
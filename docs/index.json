[{"content":" Introduzione Lo sviluppo di codice sorgente coadiuvato da sistemi di intelligenza artificiale è ormai in crescita esponenziale. Le capacità degli LLM forniti da vari provider consentono, anche in modalità Zero-Shot Learning, di generare codice sorgente di qualità con un livello di astrazione e complessità elevato. I risultati, che ritengo sorprendenti, arrivano dall\u0026rsquo;utilizzo dei cosiddetti Agent AI (in modalità ReAct e aiutati da Server MCP), migliorando la produttività degli sviluppatori.\nMa fermiamoci un attimo. Mentre il mondo è coperto di entusiasmo e aspettative, è importante ricordare che la generazione di codice sorgente da parte di un LLM (in modalità agentica e non) è solo una parte del processo di sviluppo software. La richiesta di Software Architect è destinata a rimanere alta per scongiurare il rischio di creare software che, seppur funzionante, sia poco performante, difficile da mantenere, scalare ed estendere.\nA tutti noi è capitato di partecipare a progetti software che, seppur funzionanti, avevano un debito tecnico enorme e difficile da contenere. Il tempo e i costi spesso hanno influenzato negativamente la qualità del software, portando a soluzioni quick and dirty che, sebbene risolvessero il problema immediato, aumentavano le percentuali di codice sorgente non performante e a volte anche esposto a vulnerabilità.\nLa domanda è: in una fase in cui le tecnologie stanno evolvendo rapidamente, possiamo permetterci ancora una volta lo stesso errore?\nLa risposta deve essere no, anche perché, oltre al debito tecnico, in questo caso ci sono dei costi attivi (provider di servizi AI, DB vettoriali, \u0026hellip;) da considerare non indifferenti.\nUtilizzando agenti AI senza una solida base di progettazione software, si corre il rischio di andare a braccio progettando sistemi che funzionano, ma che non sono scalabili e manutenibili. Tra i rischi troviamo:\n\u0026ldquo;over-engineering\u0026rdquo;, ovvero progettare sistemi troppo complessi per risolvere problemi semplici, con conseguente aumento dei costi attivi del progetto. performance inadeguate dovute ad una progettazione non ottimale degli Agent AI, che potrebbe portare a tempi di risposta più lunghi e a un\u0026rsquo;esperienza utente insoddisfacente. Obiettivo Con questo articolo condividerò un esercizio eseguito con lo scopo di provare alcuni agent design pattern. L\u0026rsquo;esercizio si basa su un piccolo software d\u0026rsquo;esempio chiamato Agentic TotChef, che si pone come obiettivo la generazione di un menù settimanale per una bambina di 1 anno tenendo conto di ciò che mangia all\u0026rsquo;asilo nido, dal ricettario di famiglia e da ciò che è disponibile in casa.\nL\u0026rsquo;esercizio mi ha aiutato a capire limiti e vantaggi tra cui:\nL\u0026rsquo;utlizzo di SLM (Small Language Model) in modo da contenere i costi ed ottenere risultati soddisfacenti L\u0026rsquo;adozione di design pattern e best pratice per progettare agenti AI con un buon grado di performance Small Language Model: limiti e vantaggi Se è vero che i grandi modelli linguistici (LLM) come GPT-5, Gemini, Claude, Grok e simili offrono capacità straordinarie, è altrettanto vero che i Small Language Model (SLM) stanno guadagnando terreno grazie alla loro efficienza e costi ridotti.\nI SLM, come quelli offerti da Ollama, sono progettati per essere più leggeri e meno costosi, rendendoli ideali per applicazioni specifiche che non richiedono la potenza di un LLM completo.\nTra i vantaggi:\nCosti ridotti: I SLM sono generalmente più economici da utilizzare rispetto agli LLM, rendendoli accessibili anche per progetti con budget limitati. Efficienza: I SLM possono essere più veloci nel generare risposte, soprattutto quando si tratta di compiti specifici che non richiedono una comprensione profonda del contesto. Personalizzazione: Con l\u0026rsquo;aggiunta di un contesto specifico è possibile ottenere risultati più pertinenti e accurati, sfruttando al meglio le capacità del SLM. Tuttavia, è importante riconoscere i limiti dei SLM, come la capacità di comprendere contesti complessi o di generare risposte creative. Quindi la scelta tra LLM e SLM dipende dalle esigenze specifiche del progetto e dagli obiettivi che si vogliono raggiungere.\nNel mio caso, per il progetto TotChef, ho optato per qwen3-8b, che si è dimostrato sufficiente per generare menù settimanali accurati e pertinenti. Ovviamente parliamo di requisiti di complessità medio-bassi e hardware limitato. In ogni caso quanto basta per arrivare ad un risultato soddisfacente con tempi di risposta accettabili.\nAgentic Design Patterns: un approccio per progettare agenti AI scalabili e manutenibili TotChef: Architettura software Conclusioni ","permalink":"https://carmelolg.github.io/it-is-worth-a-coke/posts/ai-agentic-flow-architecture/ai-agentic-flow-architecture_italian/","summary":"\u003c!-- Durante una sessione di lettura intensiva mi sono imbattuto su un libro molto interessante: Agentic Design Pattern di Antonio Gulli, Eng Director in Google. --\u003e\n\u003ch1 id=\"introduzione\"\u003eIntroduzione\u003c/h1\u003e\n\u003cp\u003eLo sviluppo di codice sorgente coadiuvato da sistemi di intelligenza artificiale è ormai in crescita esponenziale.\nLe capacità degli LLM forniti da vari provider consentono, anche in modalità \u003ca href=\"https://www.promptingguide.ai/techniques/zeroshot\"\u003eZero-Shot Learning\u003c/a\u003e, di generare codice sorgente di qualità con un livello di astrazione e complessità elevato.\nI risultati, che ritengo sorprendenti, arrivano dall\u0026rsquo;utilizzo dei cosiddetti \u003cstrong\u003eAgent AI\u003c/strong\u003e (in modalità \u003ca href=\"https://www.promptingguide.ai/techniques/react\"\u003eReAct\u003c/a\u003e e aiutati da \u003ca href=\"https://modelcontextprotocol.io/docs/getting-started/intro\"\u003eServer MCP\u003c/a\u003e), migliorando la produttività degli sviluppatori.\u003c/p\u003e","title":"Agentic TotChef: Architetture software, Patterns, and Best Practices"},{"content":" Introduction The development of source code assisted by artificial intelligence systems is now experiencing exponential growth. The capabilities of LLMs provided by various providers allow, even in Zero-Shot Learning mode, to generate quality source code with a high level of abstraction and complexity. The results, which I consider surprising, come from the use of so-called Agent AI (in ReAct mode and assisted by Server MCP), improving developer productivity.\nBut let\u0026rsquo;s pause for a moment. While the world is filled with enthusiasm and expectations, it is important to remember that the generation of source code by an LLM (in agentic mode or not) is only one part of the software development process. The demand for Software Architects is destined to remain high to avoid the risk of creating software that, although functional, is underperforming, difficult to maintain, scale, and extend.\nAll of us have participated in software projects that, although functional, had enormous technical debt that was difficult to contain. Time and costs have often negatively influenced software quality, leading to quick and dirty solutions that, although they solved the immediate problem, increased the percentages of underperforming source code and sometimes even exposed to vulnerabilities.\nThe question is: in a phase where technologies are evolving rapidly, can we afford to make the same mistake again?\nThe answer must be no, also because, in addition to technical debt, in this case there are active costs (AI service providers, vector databases, \u0026hellip;) to consider that are not insignificant.\nUsing AI agents without a solid foundation of software design runs the risk of haphazardly designing systems that work, but are not scalable and maintainable. Among the risks we find:\n\u0026ldquo;over-engineering\u0026rdquo;, i.e., designing overly complex systems to solve simple problems, with a consequent increase in the project\u0026rsquo;s active costs. inadequate performance due to sub-optimal design of AI Agents, which could lead to longer response times and an unsatisfactory user experience. Objective In this article, I will share an exercise performed with the aim of testing some agent design patterns. The exercise is based on a small example software called Agentic TotChef, which aims to generate a weekly menu for a 1-year-old child, taking into account what they eat at nursery school, from the family recipe book, and what is available at home.\nThe exercise helped me understand limits and advantages including:\nThe use of SLMs (Small Language Models) to contain costs and obtain satisfactory results. The adoption of design patterns and best practices for designing AI agents with a good degree of performance. Small Language Models: limits and advantages While it is true that large language models (LLMs) like GPT-5, Gemini, Claude, Grok, and the like offer extraordinary capabilities, it is equally true that Small Language Models (SLMs) are gaining ground thanks to their efficiency and reduced costs.\nSLMs, like those offered by Ollama, are designed to be lighter and less expensive, making them ideal for specific applications that do not require the power of a full LLM.\nAmong the advantages:\nReduced costs: SLMs are generally cheaper to use than LLMs, making them accessible even for projects with limited budgets. Efficiency: SLMs can be faster at generating responses, especially when dealing with specific tasks that do not require a deep understanding of the context. Personalization: With the addition of specific context, it is possible to obtain more relevant and accurate results, making the most of the SLM\u0026rsquo;s capabilities. However, it is important to recognize the limitations of SLMs, such as their ability to understand complex contexts or generate creative responses. Therefore, the choice between LLM and SLM depends on the specific needs of the project and the objectives to be achieved.\nIn my case, for the TotChef project, I opted for qwen3-8b, which proved sufficient to generate accurate and relevant weekly menus. Obviously, we are talking about medium-low complexity requirements and limited hardware. In any case, enough to achieve a satisfactory result with acceptable response times.\nAgentic Design Patterns: an approach to designing scalable and maintainable AI agents TotChef: Software Architecture Conclusions ","permalink":"https://carmelolg.github.io/it-is-worth-a-coke/posts/ai-agentic-flow-architecture/ai-agentic-flow-architecture_english/","summary":"\u003c!-- During an intensive reading session, I came across a very interesting book: Agentic Design Patterns by Antonio Gulli, Eng Director at Google. --\u003e\n\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eThe development of source code assisted by artificial intelligence systems is now experiencing exponential growth.\nThe capabilities of LLMs provided by various providers allow, even in \u003ca href=\"https://www.promptingguide.ai/techniques/zeroshot\"\u003eZero-Shot Learning\u003c/a\u003e mode, to generate quality source code with a high level of abstraction and complexity.\nThe results, which I consider surprising, come from the use of so-called \u003cstrong\u003eAgent AI\u003c/strong\u003e (in \u003ca href=\"https://www.promptingguide.ai/techniques/react\"\u003eReAct\u003c/a\u003e mode and assisted by \u003ca href=\"https://modelcontextprotocol.io/docs/getting-started/intro\"\u003eServer MCP\u003c/a\u003e), improving developer productivity.\u003c/p\u003e","title":"Agentic TotChef: Software Architectures, Patterns, and Best Practices"}]